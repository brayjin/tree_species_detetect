{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vOjkUhcviFvU"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m     filtered_df = df[selected_columns].copy()\n\u001b[32m     24\u001b[39m     df_list.append(filtered_df)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m merged_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m merged_df.insert(\u001b[32m0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtree_id\u001b[39m\u001b[33m'\u001b[39m, [\u001b[33m'\u001b[39m\u001b[33mtree_\u001b[39m\u001b[33m'\u001b[39m + \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(merged_df) + \u001b[32m1\u001b[39m)])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m op = \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[39m, in \u001b[36m_Concatenator.__init__\u001b[39m\u001b[34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28mself\u001b[39m.verify_integrity = verify_integrity\n\u001b[32m    443\u001b[39m \u001b[38;5;28mself\u001b[39m.copy = copy\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m objs, keys = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[32m    448\u001b[39m ndims = \u001b[38;5;28mself\u001b[39m._get_ndims(objs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[39m, in \u001b[36m_Concatenator._clean_keys_and_objs\u001b[39m\u001b[34m(self, objs, keys)\u001b[39m\n\u001b[32m    504\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo objects to concatenate\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    510\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(com.not_none(*objs_list))\n",
      "\u001b[31mValueError\u001b[39m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "extract_dir = \"5M_trees\"\n",
    "\n",
    "selected_columns = [\n",
    "    'common_name', 'scientific_name', 'city', 'state',\n",
    "    'longitude_coordinate', 'latitude_coordinate', 'address', 'condition',\n",
    "    'native', 'height_binned_M', 'diameter_breast_height_binned_CM',\n",
    "    'location_type', 'zipcode', 'neighborhood', 'location_name', 'ward',\n",
    "    'district', 'overhead_utility', 'diameter_breast_height_CM', 'height_M'\n",
    "]\n",
    "\n",
    "# Merge all CSVs except metadata\n",
    "exclude_files = {'Column_Headers_Dryad.csv', 'README_Dryad.txt'}\n",
    "csv_files = [f for f in glob.glob(os.path.join(extract_dir, \"*.csv\")) if os.path.basename(f) not in exclude_files]\n",
    "\n",
    "df_list = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file, low_memory=False)\n",
    "    filtered_df = df[selected_columns].copy()\n",
    "    df_list.append(filtered_df)\n",
    "\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "merged_df.insert(0, 'tree_id', ['tree_' + str(i) for i in range(1, len(merged_df) + 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "xOwn5LQXiiRo",
    "outputId": "b3cf048b-c3f1-4c0e-ab58-4a94ca85c445"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tree_id                                   0\n",
       "common_name                          892786\n",
       "scientific_name                      529298\n",
       "city                                   1899\n",
       "state                                    31\n",
       "longitude_coordinate                 751709\n",
       "latitude_coordinate                  751578\n",
       "address                             1254392\n",
       "condition                           3038500\n",
       "native                                    0\n",
       "height_binned_M                     4996887\n",
       "diameter_breast_height_binned_CM    1574755\n",
       "location_type                       3469760\n",
       "zipcode                             4770156\n",
       "neighborhood                        5132935\n",
       "location_name                       5310350\n",
       "ward                                5384826\n",
       "district                            5509706\n",
       "overhead_utility                    5017235\n",
       "diameter_breast_height_CM           2785979\n",
       "height_M                            4951094\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tFLJ_NJVit4M"
   },
   "outputs": [],
   "source": [
    "# Drop columns with more than 3,038,500 missing values\n",
    "threshold = 3038501\n",
    "merged_df = merged_df.loc[:, merged_df.isnull().sum() <= threshold]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "HX4JWJt0jHhd",
    "outputId": "ee7cdb35-942d-4b1e-9dab-625da095a4f4"
   },
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop(columns=['diameter_breast_height_binned_CM'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1KZbvRiliwT4"
   },
   "outputs": [],
   "source": [
    "merged_df = merged_df.dropna(subset=[\n",
    "    'common_name',\n",
    "    'scientific_name',\n",
    "    'longitude_coordinate',\n",
    "    'latitude_coordinate',\n",
    "    'condition',\n",
    "    'diameter_breast_height_CM','address', 'city'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "wO-S8Swii7mz",
    "outputId": "382dd608-42c1-4816-a914-e5d19125f007"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tree_id                      0\n",
       "common_name                  0\n",
       "scientific_name              0\n",
       "city                         0\n",
       "state                        0\n",
       "longitude_coordinate         0\n",
       "latitude_coordinate          0\n",
       "address                      0\n",
       "condition                    0\n",
       "native                       0\n",
       "diameter_breast_height_CM    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wtlKsJKzjADx"
   },
   "outputs": [],
   "source": [
    "# Step 0: Remove tree species with < 2 samples\n",
    "species_counts = merged_df['common_name'].value_counts()\n",
    "valid_species = species_counts[species_counts >= 3].index.tolist()\n",
    "\n",
    "# Keep only valid species\n",
    "filtered_df = merged_df[merged_df['common_name'].isin(valid_species)].copy()\n",
    "\n",
    "# Verify the filtering worked\n",
    "assert filtered_df['common_name'].value_counts().min() >= 3, \"Still has species with < 2 samples!\"\n",
    "\n",
    "# Continue with filtered data\n",
    "data = filtered_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "I3PYlq0-kz8P",
    "outputId": "c0d55f4f-6985-4a15-d288-679f331a587e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "common_name\n",
       "London planetree             87070\n",
       "Honeylocust                  75267\n",
       "Norway maple                 65983\n",
       "Pin oak                      64479\n",
       "Callery pear                 62088\n",
       "                             ...  \n",
       "Neem tree                        3\n",
       "Burgundy ussurian pear           3\n",
       "Mancana ash                      3\n",
       "White shield osage orange        3\n",
       "Arizona ash                      3\n",
       "Name: count, Length: 1497, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['common_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "oivLq3FGkuAx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0bK-BagHjM_R"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "\n",
    "# Load data\n",
    "df = filtered_df.copy()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "\n",
    "# Load data\n",
    "df = merged_df.copy()\n",
    "\n",
    "# Optional: Simplify to genus\n",
    "df['genus'] = df['scientific_name'].apply(lambda x: x.split()[0])\n",
    "\n",
    "# Encode categorical variables (native, city, state)\n",
    "df['native_encoded'] = df['native'].astype('category').cat.codes\n",
    "df['city_encoded'] = df['city'].astype('category').cat.codes\n",
    "df['state_encoded'] = df['state'].astype('category').cat.codes\n",
    "\n",
    "# Features to use\n",
    "feature_cols = ['latitude_coordinate', 'longitude_coordinate', 'diameter_breast_height_CM',\n",
    "                'native_encoded', 'city_encoded', 'state_encoded']\n",
    "X = df[feature_cols]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Fit Nearest Neighbors model\n",
    "nn_model = NearestNeighbors(n_neighbors=50, algorithm='ball_tree')  # can tune n_neighbors\n",
    "nn_model.fit(X_scaled)\n",
    "\n",
    "# Prediction function\n",
    "def recommend_species(lat, lon, diameter_cm, native, city, state, top_n=5):\n",
    "    # Encode input\n",
    "    native_code = df['native'].astype('category').cat.categories.get_loc(native)\n",
    "    city_code = df['city'].astype('category').cat.categories.get_loc(city)\n",
    "    state_code = df['state'].astype('category').cat.categories.get_loc(state)\n",
    "\n",
    "    input_features = np.array([[lat, lon, diameter_cm, native_code, city_code, state_code]])\n",
    "    input_scaled = scaler.transform(input_features)\n",
    "\n",
    "    distances, indices = nn_model.kneighbors(input_scaled)\n",
    "\n",
    "    # Get common names or genera from neighbors\n",
    "    neighbors = df.iloc[indices[0]]\n",
    "    species_counts = Counter(neighbors['common_name'])  # or use 'genus'\n",
    "\n",
    "    # Top-N species\n",
    "    top_species = species_counts.most_common(top_n)\n",
    "    return top_species\n",
    "# Optional: Simplify to genus\n",
    "df['genus'] = df['scientific_name'].apply(lambda x: x.split()[0])\n",
    "\n",
    "# Encode categorical variables (native, city, state)\n",
    "df['native_encoded'] = df['native'].astype('category').cat.codes\n",
    "df['city_encoded'] = df['city'].astype('category').cat.codes\n",
    "df['state_encoded'] = df['state'].astype('category').cat.codes\n",
    "\n",
    "# Features to use\n",
    "feature_cols = ['latitude_coordinate', 'longitude_coordinate', 'diameter_breast_height_CM',\n",
    "                'native_encoded', 'city_encoded', 'state_encoded']\n",
    "X = df[feature_cols]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Fit Nearest Neighbors model\n",
    "nn_model = NearestNeighbors(n_neighbors=50, algorithm='ball_tree')  # can tune n_neighbors\n",
    "nn_model.fit(X_scaled)\n",
    "\n",
    "# Prediction function\n",
    "def recommend_species(lat, lon, diameter_cm, native, city, state, top_n=5):\n",
    "    # Encode input\n",
    "    native_code = df['native'].astype('category').cat.categories.get_loc(native)\n",
    "    city_code = df['city'].astype('category').cat.categories.get_loc(city)\n",
    "    state_code = df['state'].astype('category').cat.categories.get_loc(state)\n",
    "\n",
    "    input_features = np.array([[lat, lon, diameter_cm, native_code, city_code, state_code]])\n",
    "    input_scaled = scaler.transform(input_features)\n",
    "\n",
    "    distances, indices = nn_model.kneighbors(input_scaled)\n",
    "\n",
    "    # Get common names or genera from neighbors\n",
    "    neighbors = df.iloc[indices[0]]\n",
    "    species_counts = Counter(neighbors['common_name'])  # or use 'genus'\n",
    "\n",
    "    # Top-N species\n",
    "    top_species = species_counts.most_common(top_n)\n",
    "    return top_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zTXlCxtRjPBR",
    "outputId": "09c1b445-cd18-49d2-d11d-f50a11be61e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bur oak (seen 4 times nearby)\n",
      "American yellowwood (seen 4 times nearby)\n",
      "Eastern hophornbeam (seen 4 times nearby)\n",
      "White oak (seen 3 times nearby)\n",
      "Shingle oak (seen 3 times nearby)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "recommendation = recommend_species(\n",
    "    lat=38.2274,\n",
    "    lon=-85.8009,\n",
    "    diameter_cm=1.2,\n",
    "    native='naturally_occurring',\n",
    "    city='Louisville',\n",
    "    state='Kentucky',\n",
    "    top_n=5\n",
    ")\n",
    "\n",
    "for species, count in recommendation:\n",
    "    print(f\"{species} (seen {count} times nearby)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8R9F79Vfp_TP",
    "outputId": "fcf90db2-5659-4fa7-d547-8feee7d274a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 2199.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 Hit Rate: 0.4990\n",
      "Mean Reciprocal Rank: 0.3479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.499, 0.3479333333333333)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "def evaluate_recommender(X_scaled, df, model, top_k=5, sample_size=1000):\n",
    "    correct = 0\n",
    "    ranks = []\n",
    "\n",
    "    for i in tqdm(range(sample_size)):\n",
    "        x_query = X_scaled[i].reshape(1, -1)\n",
    "        distances, indices = model.kneighbors(x_query)\n",
    "\n",
    "        # exclude itself\n",
    "        neighbor_indices = [idx for idx in indices[0] if idx != i][:top_k]\n",
    "        true_species = df.iloc[i]['common_name']\n",
    "        neighbor_species = df.iloc[neighbor_indices]['common_name'].tolist()\n",
    "\n",
    "        if true_species in neighbor_species:\n",
    "            correct += 1\n",
    "            ranks.append(neighbor_species.index(true_species) + 1)\n",
    "        else:\n",
    "            ranks.append(0)\n",
    "\n",
    "    hit_rate = correct / sample_size\n",
    "    mean_rank = sum([1/r for r in ranks if r > 0]) / sample_size\n",
    "\n",
    "    print(f\"Top-{top_k} Hit Rate: {hit_rate:.4f}\")\n",
    "    print(f\"Mean Reciprocal Rank: {mean_rank:.4f}\")\n",
    "    return hit_rate, mean_rank\n",
    "\n",
    "# Run evaluation on a 1000-sample subset\n",
    "evaluate_recommender(X_scaled, df, nn_model, top_k=5, sample_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJdgr_CyqPo4",
    "outputId": "e5832e0b-ba7d-4356-d959-b29a63166afb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved scaler, model and data!\n"
     ]
    }
   ],
   "source": [
    "# Save scaler and model\n",
    "import joblib\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "joblib.dump(nn_model, 'nn_model.joblib')\n",
    "\n",
    "# Also save the dataframe with encoded columns (needed for categories and lookup)\n",
    "df.to_pickle('tree_data.pkl')\n",
    "\n",
    "print(\"Saved scaler, model and data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "GsThrmF1qrg0"
   },
   "outputs": [],
   "source": [
    "def get_common_locations_for_species(tree_name, top_n=10):\n",
    "    \"\"\"\n",
    "    Given a tree common name, return the top N most frequent locations.\n",
    "    \"\"\"\n",
    "    species_df = df[df['common_name'] == tree_name]\n",
    "    \n",
    "    if species_df.empty:\n",
    "        return f\"No records found for species: {tree_name}\"\n",
    "    \n",
    "    # You can group by city/state or full address\n",
    "    location_counts = species_df.groupby(['city', 'state']) \\\n",
    "                                .size().reset_index(name='count') \\\n",
    "                                .sort_values(by='count', ascending=False) \\\n",
    "                                .head(top_n)\n",
    "    \n",
    "    return location_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top locations where 'Bur oak' is commonly found:\n",
      "            city                 state  count\n",
      "5  Washington DC  District of Columbia    760\n",
      "4       New York              New York    515\n",
      "3     Louisville              Kentucky    490\n",
      "0         Aurora              Colorado    239\n",
      "2         Durham        North Carolina     69\n"
     ]
    }
   ],
   "source": [
    "# Example tree name\n",
    "tree_name = 'Bur oak'\n",
    "top_locations = get_common_locations_for_species(tree_name, top_n=5)\n",
    "\n",
    "print(f\"Top locations where '{tree_name}' is commonly found:\")\n",
    "print(top_locations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
